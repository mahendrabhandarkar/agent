#docker-compose pull
#docker-compose up -d
#spark-submit --master spark://spark-master:7077 --packages org.apache.hudi:hudi-spark3.3-bundle_2.12:0.13.1 --class com.example.MyHudiJob   my-spark-job.jar
#spark-submit --master spark://spark-master:7077 --packages org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.2.1 my_iceberg_job.py
#
#spark.hadoop.fs.s3a.endpoint=http://minio:9000
#spark.hadoop.fs.s3a.access.key=minioadmin
#spark.hadoop.fs.s3a.secret.key=minioadmin
#spark.hadoop.fs.s3a.path.style.access=true

services:

  # Kafka (KRaft mode)
  kafka:
    image: confluentinc/cp-kafka:8.1.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data

  # Flink
  flink-jobmanager:
    image: apache/flink:1.19-scala_2.12
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    depends_on:
      - kafka

  flink-taskmanager:
    image: apache/flink:1.19-scala_2.12
    container_name: flink-taskmanager
    command: taskmanager
    depends_on:
      - flink-jobmanager

  # MinIO (object storage)
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data

  # Hive Metastore (for Iceberg/Hudi catalog)
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    environment:
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
    ports:
      - "9083:9083"
    command: >
      /opt/hive/bin/hive --service metastore
    depends_on:
      - mysql

  # MySQL (Metastore DB)
  mysql:
    image: mysql:8.0
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: metastore
      MYSQL_USER: hive
      MYSQL_PASSWORD: hive
    ports:
      - "3306:3306"
    command: --default-authentication-plugin=mysql_native_password
    volumes:
      - mysql_data:/var/lib/mysql

  # Spark
  spark-master:
    image: apache/spark:3.5.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_HIVE_METASTORE_URI=thrift://hive-metastore:9083
      - SPARK_MINIO_ENDPOINT=minio:9000
      - SPARK_MINIO_ACCESS_KEY=minioadmin
      - SPARK_MINIO_SECRET_KEY=minioadmin
    ports:
      - "7077:7077"
      - "8080:8080"
    depends_on:
      - minio
      - kafka
      - hive-metastore

  spark-worker:
    image: apache/spark:3.5.5
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_HIVE_METASTORE_URI=thrift://hive-metastore:9083
      - SPARK_MINIO_ENDPOINT=minio:9000
      - SPARK_MINIO_ACCESS_KEY=minioadmin
      - SPARK_MINIO_SECRET_KEY=minioadmin
    depends_on:
      - spark-master

volumes:
  kafka_data:
  minio_data:
  mysql_data:
