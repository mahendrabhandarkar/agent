üìå Understanding Vectors in AI Systems
What Are Vectors?

Vectors are numeric representations of data and its related context. Each vector acts like a coordinate in a multi-dimensional space, where each dimension captures a specific feature or characteristic of the data.

For example, a food item could be represented by a vector where each dimension might represent a specific attribute like its spice level, sweetness, caloric content, etc.

üîÅ How Are Vectors Created?

Vectors are generated by sending raw data (like text, images, etc.) through an embedding model.

Pipeline:

Raw Data ‚Üí Encoder (Embedding Model) ‚Üí Vector Representation


These embeddings allow us to compare, cluster, and search through large volumes of data in an efficient and meaningful way.

üîç Similarity and Distance Functions

When comparing vectors, we rely on distance or similarity functions. These determine how "close" or "related" two pieces of data are in the vector space.

Common Distance/Similarity Functions:

Euclidean Distance: Measures the straight-line distance between the ends of two vectors.

Cosine Similarity: Measures the angle between two vectors, focusing on direction rather than magnitude.

Dot Product: Also angle-based, but includes magnitude, making it useful in certain scoring scenarios.

üß† Embedding Models vs LLMs

Embedding Models are specifically designed to convert data into vector form (numerical coordinates).

LLMs (Large Language Models) are designed to generate or understand language, but they can use embeddings for better understanding of context.

Note: Embedding models only produce vectors, not answers or full responses.

üß≠ Vector Search and Indexing

Vectors can be used to search for similar items using techniques like K-Nearest Neighbors (KNN). This is efficient when data is indexed.

Components:

Index Definition: Helps organize vector data for fast retrieval.

knnVector: Performs a nearest neighbor search to find similar points.

Dimensions: The embedding model defines the vector size (e.g., 1536 for text models). For image data, dimensions may differ.

HNSW (Hierarchical Navigable Small World): A commonly used algorithm for efficient vector search.

Create a Vector Search Index:

You can apply prefilters to narrow down search results before performing the vector search.

Aggregation pipelines can be used in real time to process vector search queries and retrieve results.

‚öôÔ∏è Benchmarking and Tools

There are several open-source tools available to benchmark the performance and accuracy of your vector search and embedding models.

üìö Retrieval-Augmented Generation (RAG)

RAG combines retrieval of relevant content with generation by LLMs.

Key Features:

The LLM doesn't rely solely on its training; it uses external knowledge bases to answer questions.

Enables light personalization based on retrieved context.

Limitations:

Struggles with complex or multi-step tasks

Cannot self-refine or revise its own outputs dynamically.

Example Use Case:
Travel assistant tools like Navan can use RAG for answering user queries about itineraries, bookings, and travel policies.

üöÄ Redis and LangCache Integration

Redis has integrated embedding models for caching purposes, particularly helpful in avoiding unnecessary token consumption in LLM calls.

LangCache is Redis's embedding-based caching layer.

Re-ranking methods are used to evaluate how similar a new question is to cached responses, improving performance and cost-efficiency.

üß† Components of an AI Agent

To behave intelligently, an AI agent requires the following components:

Perception:
Mechanism for understanding the environment. Inputs can include text, images, speech, etc.

Planning and Reasoning:
This is the "brain" of the agent. It plans actions or makes decisions. In LLMs, this is often done by prompting in a way that elicits the correct response.

Tools (Actions):
Interfaces the agent uses to interact with external systems (e.g., databases, APIs, file systems).

Memory:
Keeps track of context, history, or prior actions for long-term reasoning or personalization.

üß© Embedding Models and Providers

OyazAI Embedding Model: A custom or specialized embedding model.

AWS Bedrock Service: A fully managed service that offers access to foundation models from various providers, including embedding models for use in applications.
